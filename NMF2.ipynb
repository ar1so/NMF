{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb6e2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn import decomposition\n",
    "from scipy.stats import norm\n",
    "from opnmf import model, logging\n",
    "import opnmf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57285f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifting_values_min(data) : \n",
    "\n",
    "    for col in data.columns:\n",
    "    \n",
    "        # Get column min \n",
    "        min_val = data[col].min()\n",
    "        \n",
    "        # Shift column by its min value\n",
    "        data[col] = data[col] + abs(min_val)\n",
    "        #After checking all of the columns were 0 in the min value\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a358242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    \n",
    "    # Create StandardScaler and fit \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "\n",
    "    # Transform data\n",
    "    normalized_data = scaler.transform(data)  \n",
    "    normalized_data = pd.DataFrame(normalized_data, columns=data.columns)\n",
    "    \n",
    "    #Assay the normalizide was conducted or not\n",
    "    if normalized_data[normalized_data < 0].sum().sum() == 0  : \n",
    "        data_array = normalized_data.to_numpy()\n",
    "        \n",
    "        return data_array\n",
    "    \n",
    "    else : \n",
    "        normalized_data = shifting_values_min(normalized_data)\n",
    "        data_array = normalized_data.to_numpy()\n",
    "        \n",
    "        return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68436ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stability_analysis_iterative(data_array, n_components_range, num_iterations=10000, num_perturbations=10, init='nndsvd', tolerance=0.00001, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs stability analysis for OPNMF by training models on perturbed data and evaluating component similarity iteratively.\n",
    "\n",
    "    Args:\n",
    "      data_array: The original data matrix.\n",
    "      n_components_range: A range of values for the number of components (n_components) to evaluate.\n",
    "      num_iterations: The number of iterations for stability analysis (default: 10).\n",
    "      num_perturbations: The number of perturbed data matrices to generate.\n",
    "      init: The initialization method for OPNMF (default: 'nndsvd').\n",
    "      tolerance: The tolerance parameter for OPNMF (default: 0.0001).\n",
    "      random_state: Seed for random number generation (default: 42).\n",
    "\n",
    "    Returns:\n",
    "      optimal_n_components: The optimal number of components based on stability analysis.\n",
    "      stability_coefficients: A dictionary mapping each number of components to its stability coefficient.\n",
    "      reconstruction_errors: A dictionary mapping each number of components to its reconstruction error.\n",
    "    \"\"\"\n",
    "    if random_state:\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Initialize dictionaries for results\n",
    "    stability_coefficients = {}\n",
    "    reconstruction_errors = {}\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        print(f\"\\nIteration {iteration + 1}/{num_iterations}\")\n",
    "\n",
    "        # Train OPNMF on original data to get original components\n",
    "        estimator = opnmf.model.OPNMF(n_components=max(n_components_range), init=init, tol=tolerance)\n",
    "        estimator.fit(data_array)\n",
    "        original_components = estimator.components_\n",
    "\n",
    "        for n_components in n_components_range:\n",
    "            similarities = []\n",
    "\n",
    "            for _ in range(num_perturbations):\n",
    "                # Generate perturbed data\n",
    "                perturbed_data = data_array + norm(0, 0.01).rvs(size=data_array.shape)\n",
    "                scaler = StandardScaler()\n",
    "                scaler.fit(perturbed_data)\n",
    "\n",
    "                # Transform data\n",
    "                normalized_data = scaler.transform(perturbed_data)\n",
    "                normalized_data = pd.DataFrame(normalized_data, columns=pd.DataFrame(data_array).columns)\n",
    "\n",
    "                for col in normalized_data.columns:\n",
    "                    # Get column min\n",
    "                    min_val = normalized_data[col].min()\n",
    "\n",
    "                    # Shift column by its min value\n",
    "                    normalized_data[col] = normalized_data[col] + abs(min_val)\n",
    "\n",
    "                perturbed_data_array = normalized_data.to_numpy()\n",
    "\n",
    "                # Train OPNMF model on perturbed data\n",
    "                estimator = opnmf.model.OPNMF(n_components=n_components, init=init, tol=tolerance)\n",
    "                W = estimator.fit_transform(perturbed_data_array)\n",
    "                H = estimator.components_\n",
    "\n",
    "                # Compute similarity to original components\n",
    "                similarity = compute_similarity(H, original_components)\n",
    "                similarities.append(similarity)\n",
    "\n",
    "            # Average similarities for this n_components\n",
    "            average_similarity = np.mean(similarities)\n",
    "            stability_coefficients.setdefault(n_components, []).append(average_similarity)\n",
    "\n",
    "            # Reconstruction error for this n_components\n",
    "            reconstruction_error = np.linalg.norm(perturbed_data_array - np.dot(W, H), ord='fro')\n",
    "            reconstruction_errors.setdefault(n_components, []).append(reconstruction_error)\n",
    "\n",
    "    # Calculate average stability coefficients and reconstruction errors over iterations\n",
    "    for n_components in n_components_range:\n",
    "        stability_coefficients[n_components] = np.mean(stability_coefficients[n_components])\n",
    "        reconstruction_errors[n_components] = np.mean(reconstruction_errors[n_components])\n",
    "\n",
    "    # Find optimal n_components based on highest average stability coefficient\n",
    "    optimal_n_components = max(stability_coefficients, key=stability_coefficients.get)\n",
    "\n",
    "    return optimal_n_components, stability_coefficients, reconstruction_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa1d4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stability_plot(stabilities, errors):\n",
    "    # Extract data\n",
    "    n_components = list(stabilities.keys()) \n",
    "    stability_values = list(stabilities.values())\n",
    "    error_values = list(errors.values())\n",
    "\n",
    "    # Plot \n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('n_components')\n",
    "    ax1.set_ylabel('Stability', color=color) \n",
    "    ax1.plot(n_components, stability_values, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Reconstruction Error', color=color)  \n",
    "    ax2.plot(n_components, error_values, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.invert_yaxis()   \n",
    "\n",
    "    fig.tight_layout()  \n",
    "    plt.show()\n",
    "    fig.savefig('stability_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51136b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Reading\n",
    "merge_file = pd.read_csv(\"merge.csv\")\n",
    "df = merge_file.copy()\n",
    "column_get = df.columns[1:-1]\n",
    "df_2 = df[column_get]\n",
    "df = df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "306cbdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components: 2\n",
      "Stability coefficients: {2: 134588.86707716552, 4: 95372.3467193578, 6: 77799.48405151603}\n",
      "Reconstruction errors: {2: 220.9000833798355, 4: 207.8285656309462, 6: 202.7683930533579}\n"
     ]
    }
   ],
   "source": [
    "data_array = normalization(df) # your data array\n",
    "n_components_range = (2,4,6)  # or any other range you want to test\n",
    "num_perturbations = 10  # or any other number of perturbations you want to perform\n",
    "\n",
    "optimal_n, stabilities, errors = stability_analysis(data_array, n_components_range, num_perturbations)\n",
    "\n",
    "print(\"Optimal number of components:\", optimal_n)\n",
    "print(\"Stability coefficients:\", stabilities)\n",
    "print(\"Reconstruction errors:\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal number of components: 2\n",
    "Stability coefficients: {2: 134588.86707716552, 4: 95372.3467193578, 6: 77799.48405151603}\n",
    "Reconstruction errors: {2: 220.9000833798355, 4: 207.8285656309462, 6: 202.7683930533579}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
