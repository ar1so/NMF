{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb6e2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn import decomposition\n",
    "from scipy.stats import norm\n",
    "from opnmf import model, logging\n",
    "import opnmf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57285f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifting_values_min(data) : \n",
    "\n",
    "    for col in data.columns:\n",
    "    \n",
    "        # Get column min \n",
    "        min_val = data[col].min()\n",
    "        \n",
    "        # Shift column by its min value\n",
    "        data[col] = data[col] + abs(min_val)\n",
    "        #After checking all of the columns were 0 in the min value\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a358242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    \n",
    "    # Create StandardScaler and fit \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "\n",
    "    # Transform data\n",
    "    normalized_data = scaler.transform(data)  \n",
    "    normalized_data = pd.DataFrame(normalized_data, columns=data.columns)\n",
    "    \n",
    "    #Assay the normalizide was conducted or not\n",
    "    if normalized_data[normalized_data < 0].sum().sum() == 0  : \n",
    "        data_array = normalized_data.to_numpy()\n",
    "        \n",
    "        return data_array\n",
    "    \n",
    "    else : \n",
    "        normalized_data = shifting_values_min(normalized_data)\n",
    "        data_array = normalized_data.to_numpy()\n",
    "        \n",
    "        return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68436ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stability_analysis(data_array, n_components_range, num_perturbations = 10, init = 'nndsvd', tolerance = 0.00001, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs stability analysis for OPNMF by training models on perturbed data and evaluating component similarity.\n",
    "\n",
    "    Args:\n",
    "      data_array: The original data matrix.\n",
    "      n_components_range: A range of values for the number of components (n_components) to evaluate.\n",
    "      num_perturbations: The number of perturbed data matrices to generate.\n",
    "      init: The initialization method for OPNMF (default: 'nndsvd').\n",
    "      tolerance: The tolerance parameter for OPNMF (default: 0.0001).\n",
    "\n",
    "    Returns:\n",
    "      optimal_n_components: The optimal number of components based on stability analysis.\n",
    "      stability_coefficients: A dictionary mapping each number of components to its stability coefficient.\n",
    "      reconstruction_errors: A dictionary mapping each number of components to its reconstruction error.\n",
    "    \"\"\"\n",
    "    if random_state:\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    stability_coefficients = {}\n",
    "    reconstruction_errors = {}\n",
    "\n",
    "    # Train OPNMF on original data to get original components\n",
    "    estimator = opnmf.model.OPNMF(n_components=max(n_components_range), init=init, tol=tolerance)\n",
    "    estimator.fit(data_array)\n",
    "    original_components = estimator.components_\n",
    "\n",
    "    for n_components in n_components_range:\n",
    "        similarities = []\n",
    "\n",
    "        for _ in range(num_perturbations):\n",
    "            # Generate perturbed data\n",
    "            perturbed_data = data_array + norm(0, 0.01).rvs(size=data_array.shape)\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(perturbed_data)\n",
    "\n",
    "            # Transform data\n",
    "            normalized_data = scaler.transform(perturbed_data) \n",
    "            normalized_data = pd.DataFrame(normalized_data, columns=pd.DataFrame(data_array).columns)\n",
    "            \n",
    "            for col in normalized_data.columns:\n",
    "                # Get column min \n",
    "                min_val = normalized_data[col].min()\n",
    "\n",
    "                # Shift column by its min value\n",
    "                normalized_data[col] = normalized_data[col] + abs(min_val)\n",
    "\n",
    "            perturbed_data_array = normalized_data.to_numpy()\n",
    "\n",
    "            # Train OPNMF model on perturbed data\n",
    "            estimator = opnmf.model.OPNMF(n_components=n_components, init=init, tol=tolerance)\n",
    "            W = estimator.fit_transform(perturbed_data_array)\n",
    "            H = estimator.components_\n",
    "\n",
    "            # Compute similarity to original components\n",
    "            similarity = compute_similarity(H, original_components)\n",
    "            similarities.append(similarity)\n",
    "\n",
    "        # Average similarities for this n_components\n",
    "        average_similarity = np.mean(similarities)\n",
    "        stability_coefficients[n_components] = average_similarity\n",
    "\n",
    "        # Reconstruction error for this n_components\n",
    "        reconstruction_error = np.linalg.norm(perturbed_data_array - np.dot(W, H), ord='fro')\n",
    "        reconstruction_errors[n_components] = reconstruction_error\n",
    "\n",
    "    # Find optimal n_components based on highest stability coefficient\n",
    "    optimal_n_components = max(stability_coefficients, key=stability_coefficients.get)\n",
    "\n",
    "    return optimal_n_components, stability_coefficients, reconstruction_errors\n",
    "\n",
    "def compute_similarity(components1, components2, similarity_measure='cosine'):\n",
    "    \"\"\"\n",
    "    Calculates the similarity between two sets of OPNMF components.\n",
    "\n",
    "    Args:\n",
    "      components1: A matrix of components (H) from the first OPNMF model.\n",
    "      components2: A matrix of components (H) from the second OPNMF model.\n",
    "      similarity_measure: The similarity measure to use ('cosine' or 'frobenius').\n",
    "\n",
    "    Returns:\n",
    "      similarity: The similarity score between the two sets of components.\n",
    "    \"\"\"\n",
    "\n",
    "    if similarity_measure == 'cosine':\n",
    "        similarity = np.mean(np.dot(components1, components2.T))\n",
    "    elif similarity_measure == 'frobenius':\n",
    "        similarity = np.linalg.norm(components1 - components2, ord='fro')\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid similarity measure: {similarity_measure}\")\n",
    "\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa1d4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stability_plot(stabilities, errors):\n",
    "    # Extract data\n",
    "    n_components = list(stabilities.keys()) \n",
    "    stability_values = list(stabilities.values())\n",
    "    error_values = list(errors.values())\n",
    "\n",
    "    # Plot \n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('n_components')\n",
    "    ax1.set_ylabel('Stability', color=color) \n",
    "    ax1.plot(n_components, stability_values, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Reconstruction Error', color=color)  \n",
    "    ax2.plot(n_components, error_values, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.invert_yaxis()   \n",
    "\n",
    "    fig.tight_layout()  \n",
    "    plt.show()\n",
    "    fig.savefig('stability_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51136b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Reading\n",
    "merge_file = pd.read_csv(\"merge.csv\")\n",
    "df = merge_file.copy()\n",
    "column_get = df.columns[1:-1]\n",
    "df_2 = df[column_get]\n",
    "df = df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "804b905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = normalization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9bdd18d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.15521502, 3.51111203, 4.04718404, ..., 1.97413043, 2.90267839,\n",
       "        1.65037602],\n",
       "       [4.02217214, 4.21959358, 4.61608765, ..., 1.47967261, 1.99999639,\n",
       "        0.97011588],\n",
       "       [3.14271957, 1.57344163, 3.17869491, ..., 2.94909204, 2.66087498,\n",
       "        2.97751256],\n",
       "       ...,\n",
       "       [4.11509286, 4.41202888, 2.48192696, ..., 2.86597459, 2.0363084 ,\n",
       "        2.31752112],\n",
       "       [3.69933512, 0.99147465, 3.48878136, ..., 1.60695758, 2.81276293,\n",
       "        2.33209339],\n",
       "       [4.10077989, 2.96576768, 1.48680891, ..., 3.0903917 , 2.11232154,\n",
       "        3.31717897]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "640ccada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPNMF did not converge with tolerance = 1e-05 under 50000 iterations\n",
      "/Users/ahmadrezasohrabi/opt/anaconda3/lib/python3.9/site-packages/opnmf/logging.py:168: RuntimeWarning: OPNMF did not converge with tolerance = 1e-05 under 50000 iterations\n",
      "  warnings.warn(msg, category=category)\n",
      "OPNMF did not converge with tolerance = 1e-05 under 50000 iterations\n",
      "/Users/ahmadrezasohrabi/opt/anaconda3/lib/python3.9/site-packages/opnmf/logging.py:168: RuntimeWarning: OPNMF did not converge with tolerance = 1e-05 under 50000 iterations\n",
      "  warnings.warn(msg, category=category)\n",
      "OPNMF did not converge with tolerance = 1e-05 under 50000 iterations\n",
      "/Users/ahmadrezasohrabi/opt/anaconda3/lib/python3.9/site-packages/opnmf/logging.py:168: RuntimeWarning: OPNMF did not converge with tolerance = 1e-05 under 50000 iterations\n",
      "  warnings.warn(msg, category=category)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9k/k1xv6f3d697_1t1nm64y15zm0000gn/T/ipykernel_18221/685116092.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_perturbations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# or any other number of perturbations you want to perform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moptimal_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstability_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_perturbations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimal number of components:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimal_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9k/k1xv6f3d697_1t1nm64y15zm0000gn/T/ipykernel_18221/1499474192.py\u001b[0m in \u001b[0;36mstability_analysis\u001b[0;34m(data_array, n_components_range, num_perturbations, init, tolerance, random_state)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Train OPNMF model on perturbed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPNMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_data_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/opnmf/model.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, init_W)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# Run factorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             W, H, mse = opnmf(\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 tol=self.tol, init=self.init, init_W=init_W)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/opnmf/opnmf.py\u001b[0m in \u001b[0;36mopnmf\u001b[0;34m(X, n_components, max_iter, tol, init, init_W)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-16\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             delta_W = (np.linalg.norm(old_W - W, ord='fro') /\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Duplicate axes given.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2565\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0m_multi_svd_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2566\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2567\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multi_svd_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_multi_svd_norm\u001b[0;34m(x, row_axis, col_axis, op)\u001b[0m\n\u001b[1;32m   2339\u001b[0m     \"\"\"\n\u001b[1;32m   2340\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2341\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_uv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2342\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->d'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1661\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_array = data_array # your data array\n",
    "n_components_range = (2,4,6,8,10,12,14,16)  # or any other range you want to test\n",
    "num_perturbations = 10  # or any other number of perturbations you want to perform\n",
    "\n",
    "optimal_n, stabilities, errors = stability_analysis(data_array, n_components_range, num_perturbations)\n",
    "\n",
    "print(\"Optimal number of components:\", optimal_n)\n",
    "print(\"Stability coefficients:\", stabilities)\n",
    "print(\"Reconstruction errors:\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdd210c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stability_analysis_iterative(data_array, n_components_range, num_iterations=10000, num_perturbations=10, init='nndsvd', tolerance=0.00001, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs stability analysis for OPNMF by training models on perturbed data and evaluating component similarity iteratively.\n",
    "\n",
    "    Args:\n",
    "      data_array: The original data matrix.\n",
    "      n_components_range: A range of values for the number of components (n_components) to evaluate.\n",
    "      num_iterations: The number of iterations for stability analysis (default: 10).\n",
    "      num_perturbations: The number of perturbed data matrices to generate.\n",
    "      init: The initialization method for OPNMF (default: 'nndsvd').\n",
    "      tolerance: The tolerance parameter for OPNMF (default: 0.0001).\n",
    "      random_state: Seed for random number generation (default: 42).\n",
    "\n",
    "    Returns:\n",
    "      optimal_n_components: The optimal number of components based on stability analysis.\n",
    "      stability_coefficients: A dictionary mapping each number of components to its stability coefficient.\n",
    "      reconstruction_errors: A dictionary mapping each number of components to its reconstruction error.\n",
    "    \"\"\"\n",
    "    if random_state:\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Initialize dictionaries for results\n",
    "    stability_coefficients = {}\n",
    "    reconstruction_errors = {}\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        print(f\"\\nIteration {iteration + 1}/{num_iterations}\")\n",
    "\n",
    "        # Train OPNMF on original data to get original components\n",
    "        estimator = opnmf.model.OPNMF(n_components=max(n_components_range), init=init, tol=tolerance)\n",
    "        estimator.fit(data_array)\n",
    "        original_components = estimator.components_\n",
    "\n",
    "        for n_components in n_components_range:\n",
    "            similarities = []\n",
    "\n",
    "            for _ in range(num_perturbations):\n",
    "                # Generate perturbed data\n",
    "                perturbed_data = data_array + norm(0, 0.01).rvs(size=data_array.shape)\n",
    "                scaler = StandardScaler()\n",
    "                scaler.fit(perturbed_data)\n",
    "\n",
    "                # Transform data\n",
    "                normalized_data = scaler.transform(perturbed_data)\n",
    "                normalized_data = pd.DataFrame(normalized_data, columns=pd.DataFrame(data_array).columns)\n",
    "\n",
    "                for col in normalized_data.columns:\n",
    "                    # Get column min\n",
    "                    min_val = normalized_data[col].min()\n",
    "\n",
    "                    # Shift column by its min value\n",
    "                    normalized_data[col] = normalized_data[col] + abs(min_val)\n",
    "\n",
    "                perturbed_data_array = normalized_data.to_numpy()\n",
    "\n",
    "                # Train OPNMF model on perturbed data\n",
    "                estimator = opnmf.model.OPNMF(n_components=n_components, init=init, tol=tolerance)\n",
    "                W = estimator.fit_transform(perturbed_data_array)\n",
    "                H = estimator.components_\n",
    "\n",
    "                # Compute similarity to original components\n",
    "                similarity = compute_similarity(H, original_components)\n",
    "                similarities.append(similarity)\n",
    "\n",
    "            # Average similarities for this n_components\n",
    "            average_similarity = np.mean(similarities)\n",
    "            stability_coefficients.setdefault(n_components, []).append(average_similarity)\n",
    "\n",
    "            # Reconstruction error for this n_components\n",
    "            reconstruction_error = np.linalg.norm(perturbed_data_array - np.dot(W, H), ord='fro')\n",
    "            reconstruction_errors.setdefault(n_components, []).append(reconstruction_error)\n",
    "\n",
    "    # Calculate average stability coefficients and reconstruction errors over iterations\n",
    "    for n_components in n_components_range:\n",
    "        stability_coefficients[n_components] = np.mean(stability_coefficients[n_components])\n",
    "        reconstruction_errors[n_components] = np.mean(reconstruction_errors[n_components])\n",
    "\n",
    "    # Find optimal n_components based on highest average stability coefficient\n",
    "    optimal_n_components = max(stability_coefficients, key=stability_coefficients.get)\n",
    "\n",
    "    return optimal_n_components, stability_coefficients, reconstruction_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "306cbdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components: 2\n",
      "Stability coefficients: {2: 134588.86707716552, 4: 95372.3467193578, 6: 77799.48405151603}\n",
      "Reconstruction errors: {2: 220.9000833798355, 4: 207.8285656309462, 6: 202.7683930533579}\n"
     ]
    }
   ],
   "source": [
    "data_array = data_array # your data array\n",
    "n_components_range = (2,4,6)  # or any other range you want to test\n",
    "num_perturbations = 10  # or any other number of perturbations you want to perform\n",
    "\n",
    "optimal_n, stabilities, errors = stability_analysis(data_array, n_components_range, num_perturbations)\n",
    "\n",
    "print(\"Optimal number of components:\", optimal_n)\n",
    "print(\"Stability coefficients:\", stabilities)\n",
    "print(\"Reconstruction errors:\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal number of components: 2\n",
    "Stability coefficients: {2: 134588.86707716552, 4: 95372.3467193578, 6: 77799.48405151603}\n",
    "Reconstruction errors: {2: 220.9000833798355, 4: 207.8285656309462, 6: 202.7683930533579}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
